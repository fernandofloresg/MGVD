{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import math\n",
    "import os\n",
    "import json\n",
    "import nltk\n",
    "import numpy\n",
    "from pprint import pprint  # For proper print of sequences.\n",
    "import treetaggerwrapper\n",
    "global stopWl\n",
    "\n",
    "def acentos(s):\n",
    "    ac = [\"á\",\"é\",\"í\",\"ó\",\"ú\",\"ñ\"]\n",
    "    s = s.replace(ac[0],\"a\")\n",
    "    s = s.replace(ac[1],\"e\")\n",
    "    s = s.replace(ac[2],\"i\")\n",
    "    s = s.replace(ac[3],\"o\")\n",
    "    s = s.replace(ac[4],\"u\")\n",
    "    s = s.replace(ac[5],\"n\")\n",
    "    return s\n",
    "\n",
    "def minusculas(s):\n",
    "    return s.lower()\n",
    "\n",
    "def diccionario(lista,num):\n",
    "    global dicc\n",
    "    for i in lista:\n",
    "        if i in dicc:\n",
    "            dicc[i].append(num)\n",
    "        else:\n",
    "            dicc[i] = []\n",
    "            dicc[i].append(num)\n",
    "            \n",
    "def plurarASingular(palabra):\n",
    "    if len(palabra)> 3 and palabra[-2] == 'e':\n",
    "        if palabra[-3] in ['i','u','b','c','g','m','p','t']:\n",
    "            palabra = palabra[0:-2]\n",
    "    if palabra[-1] == 's'and palabra[-2] in ['a','e','o','u']:\n",
    "            palabra = palabra[0:-1]\n",
    "    return palabra\n",
    "\n",
    "    \n",
    "\n",
    "def procesar(i):\n",
    "    global stopWl\n",
    "    l = acentos(i)\n",
    "    l= re.sub('\\W+',' ',l)\n",
    "    l = minusculas(l)\n",
    "    lista = l.split()\n",
    "    aux = []\n",
    "    for i in lista:\n",
    "        if len(i) > 2 and i not in stopWl:\n",
    "            if i[-1]==\"s\":\n",
    "                i =plurarASingular(i)\n",
    "            aux.append(i)\n",
    "    return aux\n",
    "\n",
    "def contruirifidf(tf,idf):\n",
    "    llaves = tf.keys()\n",
    "    dicc = {}\n",
    "    for i in llaves:\n",
    "        dicc[i] = tf[i]*idf[i]\n",
    "        #print(i,\" : \", dicc[i])\n",
    "    return dicc\n",
    "        \n",
    "def leerStopW(archi):\n",
    "    stopWl =[]\n",
    "    for i in archi.readlines():\n",
    "        i=i[0:-1]\n",
    "        stopWl.append(i)\n",
    "    return stopWl    \n",
    "\n",
    "def entities(txt):\n",
    "    sentences = [s for s in nltk.tokenize.sent_tokenize(txt)]\n",
    "    #normalized_sentences = [s.lower() for s in sentences]\n",
    "    \n",
    "    previous_pos = None\n",
    "    current_entity_chunk = []\n",
    "    all_entity_chunks = []\n",
    "    \n",
    "    for s in sentences:\n",
    "        tags = [treetaggerwrapper.make_tags(tagger.tag_text(s))]\n",
    "        for tag in tags:\n",
    "            for t in tag:\n",
    "                token = t[0]\n",
    "                pos   = t[1]\n",
    "                if pos == previous_pos and pos.startswith('N'):\n",
    "                    \n",
    "                    current_entity_chunk.append(token)\n",
    "                elif pos.startswith('N'):\n",
    "                    if current_entity_chunk != []:\n",
    "                        word = ' '.join(current_entity_chunk)\n",
    "                        if(word[0].isupper()):\n",
    "                            all_entity_chunks.append((' '.join(current_entity_chunk), pos))\n",
    "                    current_entity_chunk = [token]\n",
    "                previous_pos = pos\n",
    "        \n",
    "    return all_entity_chunks\n",
    "    \n",
    "def buildTagger():\n",
    "    #1) build a TreeTagger wrapper:\n",
    "    tagger = treetaggerwrapper.TreeTagger(TAGLANG='es',TAGDIR='C:/Taggers/tree-tagger-windows-3.2/TreeTagger')\n",
    "\n",
    "    entities = entities(txt)\n",
    "    # Store the tokens as an index for the document and account for frequency.\n",
    "    frec = dict()\n",
    "    for c in entities:\n",
    "        if c[0] in frec:\n",
    "            frec[c[0]] += 1\n",
    "        else:\n",
    "            frec[c[0]] = 1    \n",
    "\n",
    "    print ('Entities Frequency')\n",
    "    print ('-------------')\n",
    "    print(frec)\n",
    "    print ()\n",
    "    \n",
    "def main():\n",
    "    global stopWl, dicc\n",
    "    dicc = {}\n",
    "    dicc_tf = {}\n",
    "    dicc_idf = {}\n",
    "    dicc_tf_idf= {}\n",
    "    stopWl=[]\n",
    "    documentos = []\n",
    "    documentosOriginales = []\n",
    "    \n",
    "    stopW = open(\"StopWords.txt\", \"r+\")\n",
    "    stopWl = leerStopW(stopW)\n",
    "    stopW.close()\n",
    "\n",
    "    #archi = open(\"test.txt\",encoding='utf8')\n",
    "    path = \"C:\\\\MGVD\\\\FC\\\\\"\n",
    "    files = os.listdir(path)\n",
    "    aux =0\n",
    "    for i in files:\n",
    "        file = open(i)\n",
    "        h = file.read()\n",
    "        documentosOriginales.append(h)\n",
    "        l = procesar(h) #LIMPIEZA DE LOS DATOS\n",
    "        documentos.append(l)\n",
    "        diccionario(l,aux)\n",
    "        # contar el tf\n",
    "        size = len(l)\n",
    "        for j in l:\n",
    "            eux = l.count(j)\n",
    "            dicc_tf[j+\" \"+str(aux)] = float(eux) / float(size)\n",
    "        aux += 1\n",
    "        \n",
    "    aux +=1\n",
    "    iux = 0\n",
    "    for j in documentos:\n",
    "        for i in j:\n",
    "            dicc_idf[i+\" \"+str(iux)] = math.log10(float(aux)/float(len(dicc[i])))\n",
    "        iux+=1\n",
    "\n",
    "    dicc_tf_idf = contruirifidf(dicc_tf,dicc_idf)\n",
    "\n",
    "    \n",
    "    while (True):\n",
    "        consulta = str(input(\"Escribe tu consulta: \"))\n",
    "        consulta = procesar(consulta)\n",
    "        size = len(consulta)\n",
    "        dicc_cons_tf = {}\n",
    "        dicc_cons_idf = {}\n",
    "        \n",
    "\n",
    "        for i in consulta:\n",
    "            dicc_cons_tf[i]=float(consulta.count(i)) / float(size)\n",
    "            try :\n",
    "                dicc_cons_idf[i] = math.log10(float(aux)/float(len(dicc[i])))\n",
    "            except :\n",
    "                dicc_cons_idf[i]= 0\n",
    "\n",
    "        dicc_constfidf= contruirifidf(dicc_cons_tf,dicc_cons_idf)\n",
    "        \n",
    "        q = dicc_constfidf.keys()\n",
    "        eux = 0\n",
    "        mejor = 0\n",
    "        resultados = []\n",
    "        for i in range(aux):\n",
    "            for j in q:\n",
    "                myll=j+\" \"+str(i)\n",
    "                try :\n",
    "                    eux += dicc_constfidf[j] * dicc_tf_idf[myll]\n",
    "                except:\n",
    "                    eux = eux\n",
    "            if eux > 0 :#and eux>mejor:\n",
    "                l = [eux, documentosOriginales[i],i]\n",
    "                if resultados != []:\n",
    "                    if resultados[0][0]<l[0]:\n",
    "                        resultados.insert(0,l)\n",
    "                    elif resultados[-1][0]>l[0]:\n",
    "                            resultados.append(l)\n",
    "                    else:\n",
    "                        a = 0\n",
    "                        for i in resultados:\n",
    "                            if i[0]<l[0]:\n",
    "                                resultados.insert(a,l)\n",
    "                                break\n",
    "                            a += 1\n",
    "                else:\n",
    "                    resultados.append(l)\n",
    "##                mejor = eux\n",
    "##                print(eux)\n",
    "##                print(documentos[i])\n",
    "##                try : \n",
    "##                    print(documentosOriginales[i])\n",
    "##                except:\n",
    "##                    print (\"error al escribir el documento\")\n",
    "            eux = 0\n",
    "        for i in resultados:\n",
    "            print(i)\n",
    "        \n",
    "main()\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
